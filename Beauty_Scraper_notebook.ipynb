{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import csv\n",
    "\n",
    "HEADERS = {'user-agent':\n",
    "           'Mozilla/5.0 (Macintosh; Intel Mac OS Monterey 12_0_1) \\\n",
    "           AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a csv file with the url's to scrape\n",
    "beauty_tracker = pd.read_csv('/Users/jeAn/Desktop/python_project/trackers/BEAUTY_PRODUCT.csv', sep=',', quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "beauty_tracker_URLS = beauty_tracker.url\n",
    "beauty_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the url\n",
    "page = requests.get(beauty_tracker_URLS[0], headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object that will contain all the info in the url\n",
    "soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product title\n",
    "title = soup.find('div',{'class':\"ProductMainSection__productName\"}).get_text().strip()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prevent script from crashing when there isn't a price for the product\n",
    "try:\n",
    "    price = float(soup.find('div',{'class':\"ProductPricingPanel\"}).get_text().replace('Price', '').replace('$', ''))\n",
    "except:\n",
    "    price = ''\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Scraped data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_log = pd.DataFrame()\n",
    "\n",
    "###### tracking function - keeps cycling through url's\n",
    "\n",
    "for x, url in enumerate(beauty_tracker_URLS):\n",
    "    page = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "    \n",
    "    title = soup.find('div',{'class':\"ProductMainSection__productName\"}).get_text().strip()\n",
    "    \n",
    "    try:\n",
    "        price = float(soup.find('div',{'class':\"ProductPricingPanel\"}).get_text().replace('Price', '').replace('$', ''))\n",
    "    except:\n",
    "        price = ''\n",
    "        \n",
    "    now = datetime.now().strftime('%Y-%m-%d %Hh%Mm')\n",
    "    log = pd.DataFrame({'date': now,\n",
    "                        'code': beauty_tracker.code[x],\n",
    "                        'url': url,\n",
    "                        'title': title,\n",
    "                        'price': price,\n",
    "                        'buy_below': beauty_tracker.buy_below[x]}, index=[x])\n",
    "\n",
    "    tracker_log = tracker_log.append(log)\n",
    "    print('appended '+ beauty_tracker.code[x] +'\\n' + title + '\\n\\n')\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracker_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_log.to_excel('search_history/SEARCH_HISTORY2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Script for Automation\n",
    "\n",
    "Create a function and save as python file \\\n",
    "Set up automation to run code in the terminal daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import csv\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "HEADERS = {'user-agent':\n",
    "           'Mozilla/5.0 (Macintosh; Intel Mac OS Monterey 12_0_1) \\\n",
    "           AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15'}\n",
    "\n",
    "def search_product_list(interval_count = 1, interval_hours = 6):\n",
    "    \"\"\"\n",
    "    This function lods a csv file named TRACKER_PRODUCTS.csv, with headers: [url, code, buy_below]\n",
    "    It looks for the file under in ./trackers\n",
    "    \n",
    "    It also requires a file called SEARCH_HISTORY.xslx under the folder ./search_history to start saving the results.\n",
    "    An empty file can be used on the first time using the script.\n",
    "    \n",
    "    Both the old and the new results are then saved in a new file named SEARCH_HISTORY_{datetime}.xlsx\n",
    "    This is the file the script will use to get the history next time it runs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    interval_count : TYPE, optional\n",
    "        DESCRIPTION. The default is 1. The number of iterations you want the script to run a search on the full list.\n",
    "    interval_hours : TYPE, optional\n",
    "        DESCRIPTION. The default is 6.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    New .xlsx file with previous search history and results from current search\n",
    "\n",
    "    \"\"\"\n",
    "    beauty_tracker = pd.read_csv('./trackers/BEAUTY_PRODUCT.csv', sep=',', quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "    beauty_tracker_URLS = beauty_tracker.url\n",
    "    tracker_log = pd.DataFrame()\n",
    "    now = datetime.now().strftime('%Y-%m-%d %Hh%Mm')\n",
    "    interval = 0 # counter reset\n",
    "    \n",
    "    while interval < interval_count:\n",
    "\n",
    "        for x, url in enumerate(beauty_tracker_URLS):\n",
    "            page = requests.get(url, headers=HEADERS)\n",
    "            soup = BeautifulSoup(page.content, features=\"html.parser\")\n",
    "            \n",
    "            #product title\n",
    "            title = soup.find('div',{'class':\"ProductMainSection__productName\"}).get_text().strip()\n",
    "            \n",
    "            # to prevent script from crashing when there isn't a price for the product\n",
    "            try:\n",
    "                price = float(soup.find('div',{'class':\"ProductPricingPanel\"}).get_text().replace('Price', '').replace('$', ''))\n",
    "            except:\n",
    "                price = ''\n",
    "\n",
    "\n",
    "            log = pd.DataFrame({'date': now.replace('h',':').replace('m',''),\n",
    "                                'code': beauty_tracker.code[x], # this code comes from the BEAUTY_PRODUCT file\n",
    "                                'url': url,\n",
    "                                'title': title,\n",
    "                                'price': price,\n",
    "                                'buy_below': beauty_tracker.buy_below[x] # this price comes from the BEAUTY_PRODUCT file\n",
    "                                }, index=[x])\n",
    "\n",
    "            try:\n",
    "                if price < beauty_tracker.buy_below[x]:\n",
    "                    print('************************ ALERT! Buy the '+ beauty_tracker.code[x]+' ************************')\n",
    "                    \n",
    "                    username = '' # Put your hotmail address inside ''\n",
    "                    password = '' # Put your password inside ''\n",
    "\n",
    "                    server = smtplib.SMTP('smtp.outlook.com', 587)\n",
    "                    server.ehlo()\n",
    "                    server.starttls()\n",
    "                    server.login(username, password)\n",
    "                    msg = ('Subject: Beauty Price Alert\\n\\n\\\n",
    "                    Product: {}\\n\\nNew Price: {}\\n\\nOld Price: {}\\n\\nEnd of message'.format(beauty_tracker.code[x], price, beauty_tracker.buy_below[x]))\n",
    "                    message = MIMEMultipart()\n",
    "                    message['From'] = '' # Putyour hotmail address inside ''\n",
    "                    message['to'] = '' # Put your other email address inside ''\n",
    "                    server.sendmail('', '', msg) # put your hotmail address inside the first '' and the other email address inside the second ''.\n",
    "                    print('sent email.....')\n",
    "            except:\n",
    "                # sometimes we don't get any price, so there will be an error in the if condition above\n",
    "                pass\n",
    "\n",
    "            tracker_log = tracker_log.append(log)\n",
    "            print('appended '+ beauty_tracker.code[x] +'\\n' + title + '\\n\\n')            \n",
    "            sleep(5)\n",
    "        \n",
    "        interval += 1# counter update\n",
    "        \n",
    "        sleep(interval_hours*1*1)\n",
    "        print('end of interval '+ str(interval))\n",
    "    \n",
    "    # after the run, checks last search history record, and appends this run results to it, saving a new file\n",
    "    last_search = glob('./search_history/*.xlsx')[-1] # path to file in the folder\n",
    "    search_hist = pd.read_excel(last_search)\n",
    "    final_df = search_hist.append(tracker_log, sort=False)\n",
    "    \n",
    "    final_df.to_excel('./search_history/SEARCH_HISTORY_{}.xlsx'.format(now), index=False)\n",
    "    print('end of search')\n",
    "\n",
    "search_product_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
